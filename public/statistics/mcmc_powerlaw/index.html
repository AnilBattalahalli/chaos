<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="noindex, nofollow">
<title>Bayesian Estimates for the Parameters of a Power-law Distribution with Exponential Cutoff using Monte Carlo Methods | Chaos</title>
<meta name="keywords" content="stats, bayesian">
<meta name="description" content="$$ \gdef{\boldphi}{\boldsymbol{\phi}} \gdef{\xmin}{x_{\text{min}}} \gdef{\gammaone} {\Gamma_{\alpha}^{\prime} (1-\alpha, \lambda \xmin)} \gdef{\gammatwo}{\Gamma_{\alpha}^{\prime \prime} (1-\alpha, \lambda \xmin)} \gdef{\gammazero}{\Gamma (1-\alpha, \lambda \xmin)} $$
Introduction The power-law distribution is of the form \( f(x) \propto x^{-\alpha} \), where \( \alpha \) is called the scaling parameter. It models many natural phenomena like acoustic attenuation, Curie–Von Schweidler law, neuronal avalanches, and others. As \( x \to 0 \), \( f(x) \) diverges out of bounds. Hence, we gdefine \( \xmin \) as a lower bound for the support of the distribution function \( f(x) \).">
<meta name="author" content="">
<link rel="canonical" href="http://localhost:1313/statistics/mcmc_powerlaw/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.701463c415db744dda239fdc203968cdf462f4294fda76d5e5bcea632542e060.css" integrity="sha256-cBRjxBXbdE3aI5/cIDlozfRi9ClP2nbV5bzqYyVC4GA=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/statistics/mcmc_powerlaw/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.1/dist/katex.min.css" integrity="sha384-dbVIfZGuN1Yq7/1Ocstc1lUEm+AT+/rCkibIcC/OmWo5f0EA48Vf8CytHzGrSwbQ" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.1/dist/katex.min.js" integrity="sha384-2BKqo+exmr9su6dir+qCw08N2ZKRucY4PrGQPPWU1A7FtlCGjmEGFqXCv5nyM5Ij" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>

</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="Chaos (Alt + H)">Chaos</a>
                    <div class="logo-switches">
                        <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                            <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                                fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                                stroke-linejoin="round">
                                <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                            </svg>
                            <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                                fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                                stroke-linejoin="round">
                                <circle cx="12" cy="12" r="5"></circle>
                                <line x1="12" y1="1" x2="12" y2="3"></line>
                                <line x1="12" y1="21" x2="12" y2="23"></line>
                                <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                                <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                                <line x1="1" y1="12" x2="3" y2="12"></line>
                                <line x1="21" y1="12" x2="23" y2="12"></line>
                                <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                                <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                            </svg>
                        </button>
                    </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/statistics/" title="Statistics">
                    <span>Statistics</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/selfstudy/" title="Self Study">
                    <span>Self Study</span>
                </a>
            </li>
            <li>
                <a href="https://www.lomography.com/homes/anilbattalahalli/photos?order=trending" title="Film Photography">
                    <span>Film Photography</span>&nbsp;
                    <svg fill="none" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round"
                        stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12">
                        <path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"></path>
                        <path d="M15 3h6v6"></path>
                        <path d="M10 14L21 3"></path>
                    </svg>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/kannada/" title="Kannada">
                    <span>Kannada</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/about/" title="About Me">
                    <span>About Me</span>
                </a>
            </li>
        </ul>
    </nav>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link
        href="https://fonts.googleapis.com/css2?family=Ubuntu:ital,wght@0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap"
        rel="stylesheet">

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Oxygen:wght@300;400;700&display=swap" rel="stylesheet">

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@100..900&display=swap" rel="stylesheet">

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link
        href="https://fonts.googleapis.com/css2?family=Inter:wght@100..900&family=Merriweather:ital,wght@0,300;0,400;0,700;0,900;1,300;1,400;1,700;1,900&display=swap"
        rel="stylesheet">

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Libre+Baskerville:ital,wght@0,400;0,700;1,400&display=swap"
        rel="stylesheet">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link
        href="https://fonts.googleapis.com/css2?family=DM+Sans:ital,opsz,wght@0,9..40,100..1000;1,9..40,100..1000&display=swap"
        rel="stylesheet">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Hubballi&display=swap" rel="stylesheet">

    <link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Hubballi&family=Noto+Sans+Kannada:wght@100..900&display=swap" rel="stylesheet">
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Hubballi&family=Noto+Sans+Kannada:wght@100..900&family=Tiro+Kannada:ital@0;1&display=swap" rel="stylesheet">
</header><main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Bayesian Estimates for the Parameters of a Power-law Distribution with Exponential Cutoff using Monte Carlo Methods
    </h1>
    <div class="post-meta">

</div>
  </header> 
<figure class="entry-cover"><img loading="eager" src="http://localhost:1313/stats/mcmc_powerlaw/mcmc_powerlaw.jpeg" alt="">
        
</figure>
  <div class="post-content"><p>$$
\gdef{\boldphi}{\boldsymbol{\phi}}
\gdef{\xmin}{x_{\text{min}}}
\gdef{\gammaone}  {\Gamma_{\alpha}^{\prime} (1-\alpha, \lambda \xmin)}
\gdef{\gammatwo}{\Gamma_{\alpha}^{\prime \prime} (1-\alpha, \lambda \xmin)}
\gdef{\gammazero}{\Gamma (1-\alpha, \lambda \xmin)}
$$</p>
<h2 id="introduction">Introduction<a hidden class="anchor" aria-hidden="true" href="#introduction">#</a></h2>
<p>The power-law distribution is of the form \( f(x) \propto x^{-\alpha} \), where \( \alpha \) is called the scaling parameter. It models many natural phenomena like acoustic attenuation, Curie–Von Schweidler law, neuronal avalanches, and others. As \( x \to 0 \),  \( f(x) \) diverges out of bounds. Hence, we gdefine \( \xmin \) as a lower bound for the support of the distribution function \( f(x) \). Using this, the power-law density function can be written as</p>
<div>
$$
f(x) = \frac{\alpha-1}{\xmin}\left( \frac{x}{\xmin}\right)^{-\alpha} \ \ \ \ , \ x > \xmin
$$
</div>
<p>More generally, the power-law distribution function can be written with an exponential cutoff which is of the form \( f(x) \propto x^{-\alpha}e^{-\lambda x} \) , which is again gdefined for \( x &gt; \xmin \). While the estimation of the scaling parameter is quite straightforward with maximum likelihood estimation, or by using a variant of MLE, the estimation of the lower-bound parameter \( \xmin \) is quite challenging as it can be overestimated in favor of a high likelihood value. One way to combat this problem is by penalizing the likelihood function for higher \( \xmin \), as discussed by Olmez, et.al. Another way to solve this is by using the Bayesian approach, which allows us to impose an appropriate prior on \( \xmin \). In this research, I discuss the estimation of the parameters of a power-law distribution with an exponential cutoff in three cases -</p>
<ul>
<li>Unknown \( \alpha \), and known \( \xmin \), \( \lambda \)</li>
<li>Unknown \( \xmin \) and \( \alpha \), and known \( \lambda \)</li>
<li>Unknown \( \alpha \), \( \lambda \), and \( \xmin \)</li>
</ul>
<h2 id="methods">Methods<a hidden class="anchor" aria-hidden="true" href="#methods">#</a></h2>
<p>This section discusses the establishment of the Bayesian framework for the distribution, for the three cases involving different priors.</p>
<h3 id="probability-density-function">Probability Density Function<a hidden class="anchor" aria-hidden="true" href="#probability-density-function">#</a></h3>
<div>
$$
f(x) = C x^{-\alpha}e^{-\lambda x} 1(x > \xmin)
$$
</div>
<p>It can be easily verified using simple integration: \( C = \lambda^{1-\alpha} \ / \ \Gamma(1-\alpha, \lambda \xmin) \ \ \)
where,
\( \Gamma(1-\alpha, \lambda \xmin) \) is the upper incomplete gamma function gdefined as,</p>
<div>
$$
\Gamma(s,x) = \int_{x}^{\infty} t^{s-1} e^{-t} dt \ \ \ \ , \ x > 0
$$
</div>
<h3 id="bayesian-framework">Bayesian Framework<a hidden class="anchor" aria-hidden="true" href="#bayesian-framework">#</a></h3>
<p>A general form of the posterior distribution of the parameter space \( \boldphi \) conditioned on the given data \( \mathcal{D} \) is given by</p>
<div>
$$
p(\boldphi \ | \ \mathcal{D}) \propto_{\boldphi} \mathcal{L}(\mathcal{D}, \boldphi) \ p(\boldphi)
$$
</div>
<p>where \( \mathcal{D} = { x_1, x_2, \dots, x_n } \)</p>
<p>\( \mathcal{L}(\mathcal{D}, \boldphi) \) is the likelihood function for the samples given the parameters in the parameter space. In the case of this distribution, the existence of \( \xmin \) and the same being a parameter to be estimated (random) adds to the complexity of gdefining the likelihood function of the data given the parameters \( \boldphi = (\alpha, \lambda, \xmin) \).</p>
<div>
$$
\begin{aligned}
\mathcal{L}(\mathcal{D}, \boldphi) &= \prod_{x_i > \xmin} f(x_i|\boldphi)
\end{aligned}
$$
</div>
<p>We know that \( 0 &lt; f(x_i \ | \alpha, \lambda, \xmin) &lt; 1, \ \forall x_i &gt; \xmin \), and hence, for a given \( \mathcal{D} = {x_1, x_2, \dots, x_n} \),  \( \prod_{x_i &gt; \xmin} f(x_i \ | \alpha, \lambda, \xmin) \) decreases monotonically with \( \xmin \). To counter this problem, an appropriate prior must be specified for \( \xmin \).</p>
<div>
$$
\begin{aligned}
\mathcal{L}(\mathcal{D}, \boldphi) &= \prod_{x_i > \xmin} \frac{\lambda^{1-\alpha}} {\Gamma(1-\alpha, \lambda \xmin)} \ x_i^{-\alpha} e^{-\lambda x_i} \ 1(x_i > \xmin) \\
&= \prod_{x_i > \xmin} \frac{\lambda^{1-\alpha}} {\Gamma(1-\alpha, \lambda \xmin)} \ x_i^{-\alpha} e^{-\lambda x_i} \\
&\equiv \prod_{i = 1}^n \left[ \frac{\lambda^{1-\alpha}} {\Gamma(1-\alpha, \lambda \xmin)} \ x_i^{-\alpha} e^{-\lambda x_i} 1(x_i > \xmin) + 1(x_i \le \xmin) \right] \\
\mathcal{L}(\mathcal{D}, \boldphi) &= \prod_{i = 1}^n \left[ \frac{\lambda^{1-\alpha}} {\Gamma(1-\alpha, \lambda \xmin)} \ x_i^{-\alpha} e^{-\lambda x_i} 1(x_i > \xmin) + 1(x_i \le \xmin) \right]
\end{aligned}
$$
</div>
<p>The Bayesian framework can now be written as</p>
<div>
$$
p(\boldphi \ | \ \mathcal{D}) \propto_{\boldphi} \prod_{i = 1}^n \left[ \frac{\lambda^{1-\alpha}} {\Gamma(1-\alpha, \lambda \xmin)} \ x_i^{-\alpha} e^{-\lambda x_i} 1(x_i > \xmin) + 1(x_i \le \xmin) \right]\ \ p(\boldphi)
$$
</div>
<p>The prior distribution of \( \boldphi \) consists of joint prior of \( \alpha \), \( \lambda \) and \( \xmin \).</p>
<h3 id="jeffreys-prior-for-the-scaling-parameter">Jeffrey&rsquo;s Prior for the Scaling Parameter<a hidden class="anchor" aria-hidden="true" href="#jeffreys-prior-for-the-scaling-parameter">#</a></h3>
<p>Jeffrey&rsquo;s prior is a non-informative prior. It does not make modeling assumptions of the parameter, and the posterior function thus obtained represents the parameter given the data as best as possible.</p>
<p>Jeffrey&rsquo;s prior is given by,</p>
<div>
$$
\xi^{J}(\phi) \propto_{\phi} \sqrt{I^{F}(\phi)}
$$
</div>
<p>Here, $I^{F}(\phi)$ is the Fischer information given by,</p>
 <div>
 $$ 
 \begin{aligned}    
 &I^{F}(\phi) = E_{[X|\phi]} \left\{ \frac{\partial}{\partial \phi} \log f(X|\phi) \right\}^2 \\    
 &\text{or}, \\    
 &I^{F}(\phi) = - \ E_{[X|\phi]} \left\{ \frac{\partial^2}{\partial \phi^2} \log f(X|\phi) \right\} 
 \end{aligned} 
 $$ 
 </div>
<p>To obtain the Jeffrey&rsquo;s prior for the scaling parameter, we need</p>
<div>
 $$
\begin{aligned}
   I^{F}(\alpha) &amp;= - \ E_{[X|\alpha]} \left\{ \frac{\partial^2}{\partial \alpha^2} \log f(X|\alpha) \right\}\\
   &amp;= - \ E_{[X|\alpha]} \frac{\partial^2}{\partial \alpha^2} \log \left[ \frac{\lambda^{1-\alpha}} {\Gamma(1-\alpha, \lambda \xmin)} \ x^{-\alpha} e^{-\lambda x} \ 1(x &gt; \xmin) \right]  \\
   &amp;= - \ E_{[X|\alpha]} \frac{\partial^2}{\partial \alpha^2} 
   \left[ -\alpha \log x - \lambda x +(1-\alpha) \log \lambda + \log1(x&gt;\xmin)-
   \log \Gamma(1-\alpha, \lambda \xmin) \right]  \\
   &amp;= - \ E_{[X|\alpha]} \frac{\partial}{\partial \alpha} 
   \left[ -\log x - \log \lambda - \frac{\Gamma_{\alpha}^{\prime} (1-\alpha, \lambda \xmin)}{\Gamma_{\alpha} (1-\alpha, \lambda \xmin)} \right]\\
   &amp;= - \ E_{[X|\alpha]} \left[\frac {\gammaone^2 \ - \ [\gammazero \ \gammatwo]}{\gammazero^2} \right]\\
   I^{F}(\alpha) &amp;= \frac {[\gammazero \ \gammatwo] \ - \ \gammaone^2 }{\gammazero^2}
\end{aligned}
$$
</div>
<p>Here, \( \gammaone \) is the first partial derivative of \( \gammazero \) with respect to \( \alpha \), \( \frac{\partial}{\partial \alpha} \gammazero \), and \( \gammatwo \) is the second partial derivative of \( \gammazero \) with respect to \( \alpha \), \( \frac{\partial^2}{\partial \alpha^2} \gammazero \).</p>
<div>
$$
\begin{aligned}
   \gammaone &amp;= \frac{\partial}{\partial \alpha} \gammazero \\
    &amp;= \frac{\partial}{\partial \alpha} \left[ \int_{\lambda \xmin}^{\infty} t^{-\alpha} e^{-t} dt \right]\\
    &amp;= \int_{\lambda \xmin}^{\infty} \frac{\partial}{\partial \alpha} (t^{-\alpha}) e^{-t} dt \\
    &amp;= \int_{\lambda \xmin}^{\infty} -\alpha t^{-\alpha-1} e^{-t} dt \\
    \gammaone &amp;= -\alpha \Gamma(-\alpha, \lambda \xmin)\\ \\
    \gammatwo &amp;= \frac{\partial}{\partial \alpha} [-\alpha \Gamma(-\alpha, \lambda \xmin)]\\
    &amp;= -\Gamma(-\alpha, \lambda \xmin) - \alpha \int_{\lambda \xmin}^{\infty} (-\alpha-1) t^{-\alpha-2} e^{-t} dt \\
    \gammatwo &amp;=  \alpha (\alpha + 1) \Gamma(-1-\alpha, \lambda \xmin) -\Gamma(-\alpha, \lambda \xmin)
\end{aligned}
$$
</div>
<p>Hence, our Jeffrey&rsquo;s prior can be simplified to,</p>
<div>
$$
\begin{aligned}
   \xi^{J}(\phi) &amp;\propto_{\phi} \sqrt{I^{F}(\phi)}\\
   &amp;\propto_{\phi} \sqrt{\frac {[\gammazero \ \gammatwo] \ - \ \gammaone^2 }{\gammazero^2} } \\
   \xi^{J}(\alpha | \ \lambda, \xmin) &amp;\propto_{\alpha} \sqrt{\frac {[\gammazero \ \{\alpha (\alpha + 1) \Gamma(-1-\alpha, \lambda \xmin) -\Gamma(-\alpha, \lambda \xmin)\}] \ - \ (\alpha \Gamma(-\alpha, \lambda \xmin))^2 }{\gammazero^2}}
\end{aligned}
$$
</div>
<p>Priors for the three cases -</p>
<ul>
<li><strong>Known \( \xmin \), \( \lambda \), and unknown \( \alpha \):</strong>
In this case, we can use Jeffrey&rsquo;s prior on \( \alpha \) as it is the only parameter to be estimated. Our posterior is of the form,</li>
</ul>
<div>
$$
p(\boldphi \ | \ \mathcal{D}) \propto_{\boldphi} \prod_{i = 1}^n \left[ \frac{\lambda^{1-\alpha}} {\Gamma(1-\alpha, \lambda \xmin)} \ x_i^{-\alpha} e^{-\lambda x_i} 1(x_i > \xmin) + 1(x_i \le \xmin) \right] \xi^{J}(\alpha)
$$
</div>
<p>where \( \xi^{J}(\alpha) \) is the Jeffrey&rsquo;s prior at \( \alpha \)</p>
<ul>
<li>
<p><strong>Known \( \lambda \), and unknown \( \xmin \) and \( \alpha \):</strong> In this case, we can use a uniform prior on \( \alpha \), and an exponential prior with lower and upper bounds on \( \xmin \) which would discourage higher values of \( \xmin \) on the posterior as discussed before.
$$
p(\boldphi \ | \ \mathcal{D}) \propto_{\boldphi} \prod_{i = 1}^n \left[ \frac{\lambda^{1-\alpha}} {\Gamma(1-\alpha, \lambda \xmin)} \ x_i^{-\alpha} e^{-\lambda x_i} 1(x_i &gt; \xmin) + 1(x_i \le \xmin) \right] f_{\alpha}(a) \ f_{\xmin}(x)
$$
where, \( f_{\alpha}(a) \equiv \text{U}(2,3) \) and \( f_{\xmin}(x) \propto e^{-10x} \ 1(x&gt;1) 1(x&lt;3) \)</p>
</li>
<li>
<p><strong>Unknown \( \alpha \), \( \lambda \), and \( \xmin \):</strong> In this case, since all three parameters are to be estimated, we use informative priors on each of the parameters. In this case, we use exponential distributions with upper and lower-bound cutoffs on each of them.
$$
p(\boldphi \ | \ \mathcal{D}) \propto_{\boldphi} \prod_{i = 1}^n \left[ \frac{\lambda^{1-\alpha}} {\Gamma(1-\alpha, \lambda \xmin)} \ x_i^{-\alpha} e^{-\lambda x_i} 1(x_i &gt; \xmin) + 1(x_i \le \xmin) \right] f_{\alpha}(a) \ f_{\lambda}(l) \ f_{\xmin}(x)
$$
where, \( f_{\alpha}(a) \propto e^{-10a} \ 1(a&gt;2) 1(a&lt;3) \), \( f_{\lambda}(l) \propto e^{-10l} \ 1(l&gt;0) 1(l&lt;3) \) and \( f_{\xmin}(x) \propto e^{-10x} \ 1(x&gt;1) 1(x&lt;3) \)</p>
</li>
</ul>
<h2 id="simulation">Simulation<a hidden class="anchor" aria-hidden="true" href="#simulation">#</a></h2>
<p>Simulation involves the generation of power-law samples with exponential cutoffs, with true parameters, and the estimation of these parameters. The distribution is complex to sample from using traditional methods like inverse-transform sampling, and hence, we have to use Monte Carlo methods to draw samples. None of our priors are conjugate priors, and we do not have a close-form solution for the posterior. Therefore, to perform parameter estimation, we would need to use Monte Carlo methods.</p>
<h3 id="generation-of-the-power-law-samples-with-exponential-cutoff">Generation of the power-law samples with exponential cutoff<a hidden class="anchor" aria-hidden="true" href="#generation-of-the-power-law-samples-with-exponential-cutoff">#</a></h3>
<p>Since direct sampling is difficult, we can use Accept-Reject sampling to sample from the distribution. For Accept-Reject sampling, we need to use a covering distribution \( g(x) \) for which \( M g(x) \ge l(x) \) where \( M \) is a scalar, and \( l(x) = c \pi(x) \) where \( \pi(x) \) is the power-law distribution with exponential cutoff. We can use a traditional power-law distribution (no exponential cut-off) as a covering distribution, as the density of the exponential cutoff declines faster than the traditional power-law distribution.</p>
<p>The probability density function of a traditional power-law distribution is given by,</p>
<p>$$
g(x\ | \ x_m,\alpha) = \frac{\alpha-1}{x_m} \left(\frac{x}{x_m}\right)^{-\alpha} \ , \ x&gt;x_m
$$</p>
<p>Now we use inverse transform sampling to draw samples from the traditional power-law distribution using uniform random samples.</p>
<div>
$$
\begin{aligned}
G(x) &= \int_{-\infty}^x g(x\ | \ x_m,\alpha) \ dx\\
&= \int_{-\infty}^x \frac{\alpha-1}{x_m} \left(\frac{x}{x_m}\right)^{-\alpha} I(x>x_m) \ dx \\
&= \int_{x_m}^x \frac{\alpha-1}{x_m} \left(\frac{x}{x_m}\right)^{-\alpha} \ dx \\
G(x) &= 1- \left( \frac{x}{x_m} \right)^{-\alpha+1}\\
u &= 1- \left( \frac{x}{\xmin} \right)^{-\alpha+1}\\
x &= \xmin(1-u)^{\frac{1}{1-\alpha}}
\end{aligned}
$$
</div>
<p>Here, \( x \) is a sample from the distribution \( g(x|\alpha, \lambda, \xmin) \). It can be shown that,</p>
<div>
$$
M = \frac{\lambda^{1-\alpha}  \ e^{-\lambda \xmin} \ \xmin} {(\alpha-1) \ \Gamma(1-\alpha, \lambda \xmin) \ \xmin^{\alpha}}
$$
</div>
<p>where, \( M \) satisfies the condition, \( M g(x) \ge l(x) \)</p>
<h4 id="accept-reject-algorithm">Accept-Reject algorithm<a hidden class="anchor" aria-hidden="true" href="#accept-reject-algorithm">#</a></h4>
<ul>
<li>Draw \( x \) from \( g() \)</li>
<li>Compute \(  \) r = \frac{l(x)}{M g(x)} \ (\le 1) \(  \)</li>
<li>Draw \( f=\text{Bernoulli}(r) \)</li>
<li>if \( f = 1 \), accept and return \( x \)</li>
<li>if \( f = 0 \), reject \( x \)</li>
</ul>
<h4 id="accept-rejection-sampling-to-generate-power-law-samples-with-exponential-cutoff-in-r">Accept-Rejection sampling to generate Power Law samples with Exponential Cutoff in R<a hidden class="anchor" aria-hidden="true" href="#accept-rejection-sampling-to-generate-power-law-samples-with-exponential-cutoff-in-r">#</a></h4>
<p>Import the necessary libraries and set a seed</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span><span style="color:#a6e22e">set.seed</span>(<span style="color:#ae81ff">84884</span>)
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">library</span>(expint)
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">library</span>(remotes)
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">library</span>(sigmoid)
</span></span></code></pre></div><p>Set the true-parameters</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span>alpha <span style="color:#f92672">&lt;-</span> <span style="color:#ae81ff">2.2</span>
</span></span><span style="display:flex;"><span>lambda <span style="color:#f92672">&lt;-</span> <span style="color:#ae81ff">0.3</span>
</span></span><span style="display:flex;"><span>xmin <span style="color:#f92672">&lt;-</span> <span style="color:#ae81ff">1.1</span>
</span></span><span style="display:flex;"><span>theta_true <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">c</span>(alpha, lambda, xmin)
</span></span><span style="display:flex;"><span>c <span style="color:#f92672">&lt;-</span>  lambda<span style="color:#a6e22e">^</span>(<span style="color:#ae81ff">1</span><span style="color:#f92672">-</span>alpha)<span style="color:#f92672">/</span>(<span style="color:#a6e22e">gammainc</span>(<span style="color:#ae81ff">1</span><span style="color:#f92672">-</span>alpha, lambda<span style="color:#f92672">*</span>xmin))
</span></span></code></pre></div><p>Write a function for the PDF of the power-law distribution with an exponential cutoff</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span>fp <span style="color:#f92672">&lt;-</span> <span style="color:#66d9ef">function</span>(x){
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">if</span> (x <span style="color:#f92672">&gt;</span> xmin){
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">return</span>(c <span style="color:#f92672">*</span> ((x<span style="color:#a6e22e">^ </span>(<span style="color:#ae81ff">-1</span> <span style="color:#f92672">*</span> alpha)) <span style="color:#f92672">*</span> (<span style="color:#a6e22e">exp</span>(<span style="color:#ae81ff">-1</span> <span style="color:#f92672">*</span> lambda <span style="color:#f92672">*</span> x))))
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">else</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span>(<span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Write functions to sample from the covering distribution (vanilla power-law)</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span>foo <span style="color:#f92672">&lt;-</span> <span style="color:#66d9ef">function</span>(xmin, alpha){
</span></span><span style="display:flex;"><span>  u <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">runif</span>(<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">0</span>,<span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">return</span>(xmin<span style="color:#f92672">*</span>((<span style="color:#ae81ff">1</span><span style="color:#f92672">-</span>u)<span style="color:#a6e22e">^</span>(<span style="color:#ae81ff">1</span><span style="color:#f92672">/</span>(<span style="color:#ae81ff">1</span><span style="color:#f92672">-</span>alpha))))
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>generate <span style="color:#f92672">&lt;-</span> <span style="color:#66d9ef">function</span>(n, xmin, alpha){
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">return</span>(<span style="color:#a6e22e">as.numeric</span>(<span style="color:#a6e22e">replicate</span>(n, <span style="color:#a6e22e">foo</span>(xmin, alpha), simplify<span style="color:#f92672">=</span><span style="color:#66d9ef">FALSE</span>)))
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>getCumulative <span style="color:#f92672">&lt;-</span> <span style="color:#66d9ef">function</span>(x, xmin, alpha){
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">return</span>(<span style="color:#ae81ff">1</span><span style="color:#f92672">-</span>((x<span style="color:#f92672">/</span>xmin)<span style="color:#a6e22e">^</span>(<span style="color:#ae81ff">1</span><span style="color:#f92672">-</span>alpha)))
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>covering <span style="color:#f92672">&lt;-</span> <span style="color:#66d9ef">function</span>(i){
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">return</span>(<span style="color:#a6e22e">generate</span>(<span style="color:#ae81ff">1</span>, xmin, alpha))
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Write a function to obtain the PDF of the covering distribution</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span>c_c <span style="color:#f92672">&lt;-</span> ((alpha<span style="color:#ae81ff">-1</span>)<span style="color:#f92672">/</span>xmin) <span style="color:#f92672">*</span> (xmin^alpha)
</span></span><span style="display:flex;"><span>covering_pdf <span style="color:#f92672">&lt;-</span> <span style="color:#66d9ef">function</span>(x){
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">if</span> (x <span style="color:#f92672">&gt;</span> xmin){
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span>(((alpha<span style="color:#ae81ff">-1</span>)<span style="color:#f92672">/</span>xmin)<span style="color:#f92672">*</span>((x<span style="color:#f92672">/</span>xmin)<span style="color:#a6e22e">^</span>(<span style="color:#f92672">-</span>alpha)))
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">else</span>{
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span>(<span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>M <span style="color:#f92672">&lt;-</span> c<span style="color:#f92672">*</span>(<span style="color:#a6e22e">exp</span>(<span style="color:#f92672">-</span>lambda<span style="color:#f92672">*</span>(xmin)))<span style="color:#f92672">/</span>c_c
</span></span></code></pre></div><p>I usually like to write a helper function to calculate the Accept-Reject ratio</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span>compute_ratio <span style="color:#f92672">&lt;-</span> <span style="color:#66d9ef">function</span>(u){
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">return</span>(<span style="color:#a6e22e">fp</span>(u)<span style="color:#f92672">/</span>(M<span style="color:#f92672">*</span><span style="color:#a6e22e">covering_pdf</span>(u)))
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Perform Accept-Reject sampling</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span>samples <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">list</span>()
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> (i <span style="color:#66d9ef">in</span> <span style="color:#ae81ff">1</span><span style="color:#f92672">:</span><span style="color:#ae81ff">500</span>){
</span></span><span style="display:flex;"><span>  sample <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">covering</span>()
</span></span><span style="display:flex;"><span>  r <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">compute_ratio</span>(sample)
</span></span><span style="display:flex;"><span>  result <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">rbinom</span>(<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">1</span>,prob<span style="color:#f92672">=</span>r)
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">if</span> (result <span style="color:#f92672">==</span> <span style="color:#ae81ff">1</span>){
</span></span><span style="display:flex;"><span>    samples <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">c</span>(samples, sample)
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>samplesPL <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">as.numeric</span>(samples)
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">length</span>(samplesPL)
</span></span></code></pre></div><p>We can now plot the density of the power-law samples obtained from the Accept-Reject sampling method</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span><span style="color:#a6e22e">plot</span>(<span style="color:#a6e22e">density</span>(samplesPL), xlab <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;x&#34;</span>, ylab <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;Frequency&#34;</span>, main<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Density&#34;</span>)
</span></span></code></pre></div><p><img loading="lazy" src="/stats/mcmc_powerlaw/mcmc_acceptreject.png" alt="mcmcpowerlaw"  />
</p>
<p style="text-align: center; font-style: italic; color: #808080;"><small>Density of samples obtained from accept-reject sampling</small></p>
<h3 id="bayesian-inference-on-the-parameters">Bayesian inference on the parameters<a hidden class="anchor" aria-hidden="true" href="#bayesian-inference-on-the-parameters">#</a></h3>
<p>Bayesian inference using Monte Carlo methods involves sampling from the posterior to find the parameter that gives the highest value on the posterior (mode of the posterior distribution). Since in case 2 and case 3, we need to estimate more than one parameter, our sampling from the posterior involves drawing random vectors from the posterior. In this case, we use the Metropolis-Hasting algorithm for drawing samples from the posterior. Given a proposal distribution \( q(\boldsymbol{\phi_i} | \boldsymbol{\phi_{i-1}}) \) and the likelihood function \( \mathcal{L}(\mathcal{D}, \boldphi) \).</p>
<ul>
<li>Start with \( \boldsymbol{\phi_0} \)</li>
<li>For \( i=1, 2, \dots n \):
<ul>
<li>Draw \( \boldsymbol{\phi^*} \) from \( q(\boldsymbol{\phi_{i-1}}) \)</li>
<li>Compute \( a = \frac{\mathcal{L}(\mathcal{D}, \boldsymbol{\phi^*}) q(\boldsymbol{\phi_{i-1}} | \boldsymbol{\phi^*})}{\mathcal{L}(\mathcal{D}, \boldsymbol{\phi_{i-1}}) q(\boldsymbol{\phi^*} | \boldsymbol{\phi_{i-1}})} \)</li>
<li>if \( a &gt; 1 \), accept \( \boldsymbol{\phi^*} \), \( \boldsymbol{\phi_i} = \boldsymbol{\phi^*} \)</li>
<li>if \( 0 &lt; a &lt; 1 \), accept \( \boldsymbol{\phi^*} \), \( \boldsymbol{\phi_i} = \boldsymbol{\phi^*} \) with probability \( a \)</li>
</ul>
</li>
</ul>
<p>Our proposal distributions, like prior distributions, vary with each case.</p>
<ul>
<li>Case 1:</li>
</ul>
<div>
$$ 
q(x | \boldsymbol{\phi_{i-1}}) = \boldsymbol{\phi_{i-1}} e^{\boldsymbol{\phi_{i-1}} \ x} \ 1(1&gt;0) 
$$
</div>
<ul>
<li>Case 2:</li>
</ul>
<div>
$$ 
\boldsymbol{q}(\boldsymbol{x} | \boldsymbol{\phi_{i-1}}) =
\begin{bmatrix}
\boldsymbol{\phi_{i-1}}^{[1]} e^{\boldsymbol{\phi_{i-1}}^{[1]} \ x_1} \ 1(x_1&gt;0) \\ \boldsymbol{\phi_{i-1}}^{[2]} e^{\boldsymbol{\phi_{i-1}}^{[2]} \ x_2} \ 1(x_2&gt;0) \\
\end{bmatrix}
$$
</div>
<ul>
<li>Case 3:</li>
</ul>
<div>
$$
\boldsymbol{q}(\boldsymbol{x} | \boldsymbol{\phi_{i-1}})=
\begin{bmatrix}
\boldsymbol{\phi_{i-1}}^{[1]} e^{\boldsymbol{\phi_{i-1}}^{[1]} \ x_1} \ 1(x_1&gt;0) \\ \boldsymbol{\phi_{i-1}}^{[2]} e^{\boldsymbol{\phi_{i-1}}^{[2]} \ x_2} \ 1(x_2&gt;0) \\
\boldsymbol{\phi_{i-1}}^{[3]} e^{\boldsymbol{\phi_{i-1}}^{[3]} \ x_3} \ 1(x_3&gt;0)\\
\end{bmatrix}
$$
</div>
<p><strong>Case 1 :</strong></p>
<ol>
<li>\( \alpha \) - Jeffrey&rsquo;s prior</li>
<li>\( \lambda \) - known</li>
<li>\( \xmin \) - known</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span>lambda <span style="color:#f92672">&lt;-</span> theta_true[2]
</span></span><span style="display:flex;"><span>xmin <span style="color:#f92672">&lt;-</span> theta_true[3]
</span></span></code></pre></div><p>Gamma function</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span>G <span style="color:#f92672">&lt;-</span> <span style="color:#66d9ef">function</span>(alpha){
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">suppressWarnings</span>(<span style="color:#a6e22e">gammainc</span>(<span style="color:#ae81ff">1</span><span style="color:#f92672">-</span>alpha, lambda<span style="color:#f92672">*</span>xmin))
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>The first derivative of the Gamma function</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span>Gp1 <span style="color:#f92672">&lt;-</span> <span style="color:#66d9ef">function</span>(alpha){
</span></span><span style="display:flex;"><span>  <span style="color:#ae81ff">-1</span> <span style="color:#f92672">*</span> alpha <span style="color:#f92672">*</span> <span style="color:#a6e22e">suppressWarnings</span>(<span style="color:#a6e22e">gammainc</span>(<span style="color:#ae81ff">-1</span><span style="color:#f92672">*</span>alpha, lambda<span style="color:#f92672">*</span>xmin))
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>The second derivative of the Gamma function</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span>Gp2 <span style="color:#f92672">&lt;-</span> <span style="color:#66d9ef">function</span>(alpha){
</span></span><span style="display:flex;"><span>  (alpha<span style="color:#f92672">*</span>(alpha<span style="color:#ae81ff">+1</span>)<span style="color:#f92672">*</span><span style="color:#a6e22e">suppressWarnings</span>(<span style="color:#a6e22e">gammainc</span>(<span style="color:#ae81ff">-1</span><span style="color:#f92672">-</span>alpha, lambda<span style="color:#f92672">*</span>xmin))) <span style="color:#f92672">-</span> <span style="color:#a6e22e">suppressWarnings</span>(<span style="color:#a6e22e">gammainc</span>(<span style="color:#ae81ff">-1</span><span style="color:#f92672">*</span>alpha, lambda<span style="color:#f92672">*</span>xmin))
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span>prior_alpha <span style="color:#f92672">&lt;-</span> <span style="color:#66d9ef">function</span>(alpha){
</span></span><span style="display:flex;"><span>    j <span style="color:#f92672">&lt;-</span> ((<span style="color:#a6e22e">G</span>(alpha)<span style="color:#f92672">*</span><span style="color:#a6e22e">Gp2</span>(alpha))<span style="color:#f92672">-</span>(<span style="color:#a6e22e">Gp1</span>(alpha)^2))<span style="color:#f92672">/</span>(<span style="color:#a6e22e">G</span>(alpha)^2)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> (<span style="color:#a6e22e">is.na</span>(j)){
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">return</span>(<span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> (j <span style="color:#f92672">&lt;</span> <span style="color:#ae81ff">0</span>){
</span></span><span style="display:flex;"><span>      j <span style="color:#f92672">&lt;-</span> j<span style="color:#f92672">*</span><span style="color:#ae81ff">-1</span>
</span></span><span style="display:flex;"><span>    } <span style="color:#66d9ef">else</span>{
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">return</span>(<span style="color:#a6e22e">sqrt</span>(j))
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span>pllikelihood <span style="color:#f92672">&lt;-</span> <span style="color:#66d9ef">function</span>(x, alpha){
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">if</span> (x <span style="color:#f92672">&gt;</span> xmin){
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span>(((x<span style="color:#a6e22e">^</span>(<span style="color:#f92672">-</span>alpha)) <span style="color:#f92672">*</span> <span style="color:#a6e22e">exp</span>(<span style="color:#f92672">-</span>lambda <span style="color:#f92672">*</span> x) <span style="color:#f92672">*</span> (lambda<span style="color:#a6e22e">^</span>(<span style="color:#ae81ff">1</span> <span style="color:#f92672">-</span> alpha)))<span style="color:#f92672">/</span><span style="color:#a6e22e">suppressWarnings</span>(<span style="color:#a6e22e">gammainc</span>(<span style="color:#ae81ff">1</span><span style="color:#f92672">-</span>alpha, lambda <span style="color:#f92672">*</span> xmin)))
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">else</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span>(<span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span>loglikelihood <span style="color:#f92672">&lt;-</span> <span style="color:#66d9ef">function</span>(data, alpha){
</span></span><span style="display:flex;"><span>  lik <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">lapply</span>(data, pllikelihood,  alpha<span style="color:#f92672">=</span>alpha)
</span></span><span style="display:flex;"><span>  blee <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">lapply</span>(lik, log)
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">return</span>(<span style="color:#a6e22e">sum</span>(<span style="color:#a6e22e">as.numeric</span>(blee)))
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Posterior distribution known up to a constant</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span>logpostfunc <span style="color:#f92672">&lt;-</span> <span style="color:#66d9ef">function</span>(data, alpha){
</span></span><span style="display:flex;"><span>  alpha <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">as.numeric</span>(alpha)
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">return</span>(<span style="color:#a6e22e">loglikelihood</span>(data, alpha)<span style="color:#f92672">+</span><span style="color:#a6e22e">log</span>(<span style="color:#a6e22e">prior_alpha</span>(alpha)))
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Proposal distribution</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span>proposal <span style="color:#f92672">&lt;-</span> <span style="color:#66d9ef">function</span>(given){
</span></span><span style="display:flex;"><span>  k <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">as.numeric</span>(given)
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">return</span>(<span style="color:#a6e22e">rexp</span>(<span style="color:#ae81ff">1</span>, k))
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span>proposal_pdf <span style="color:#f92672">&lt;-</span> <span style="color:#66d9ef">function</span>(this, given){
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">return</span>(<span style="color:#a6e22e">dexp</span>(<span style="color:#a6e22e">as.numeric</span>(this), <span style="color:#a6e22e">as.numeric</span>(given)))
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Metropolis-Hasting for Bayesian Inference</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span>reps <span style="color:#f92672">&lt;-</span> <span style="color:#ae81ff">100</span>
</span></span><span style="display:flex;"><span>acc <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">list</span>()
</span></span><span style="display:flex;"><span>params <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">list</span>()
</span></span><span style="display:flex;"><span>pb <span style="color:#f92672">=</span> <span style="color:#a6e22e">txtProgressBar</span>(min <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>, max <span style="color:#f92672">=</span> reps, initial <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> (v <span style="color:#66d9ef">in</span> <span style="color:#ae81ff">1</span><span style="color:#f92672">:</span>reps){
</span></span><span style="display:flex;"><span>  nit <span style="color:#f92672">&lt;-</span> <span style="color:#ae81ff">100</span>
</span></span><span style="display:flex;"><span>  accepted <span style="color:#f92672">&lt;-</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>  theta <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">list</span>()
</span></span><span style="display:flex;"><span>  theta[1] <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">proposal</span>(<span style="color:#ae81ff">2.1</span>)
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">for</span>(i <span style="color:#66d9ef">in</span> <span style="color:#ae81ff">2</span><span style="color:#f92672">:</span>nit){
</span></span><span style="display:flex;"><span>    theta_star <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">proposal</span>(theta[i<span style="color:#ae81ff">-1</span>])
</span></span><span style="display:flex;"><span>    a <span style="color:#f92672">=</span> (<span style="color:#a6e22e">logpostfunc</span>(samplesPL, theta_star) <span style="color:#f92672">+</span> <span style="color:#a6e22e">log</span>(<span style="color:#a6e22e">proposal_pdf</span>(theta[i<span style="color:#ae81ff">-1</span>], 
</span></span><span style="display:flex;"><span>                    theta_star)))<span style="color:#f92672">-</span><span style="color:#a6e22e">logpostfunc</span>(samplesPL,theta[i<span style="color:#ae81ff">-1</span>]) <span style="color:#f92672">-</span> <span style="color:#a6e22e">log</span>(<span style="color:#a6e22e">proposal_pdf</span>(theta_star,theta[i<span style="color:#ae81ff">-1</span>]))
</span></span><span style="display:flex;"><span>    a <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">exp</span>(a)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> (<span style="color:#a6e22e">is.nan</span>(a)){
</span></span><span style="display:flex;"><span>      theta[i] <span style="color:#f92672">&lt;-</span>  theta[i<span style="color:#ae81ff">-1</span>]
</span></span><span style="display:flex;"><span>    } <span style="color:#66d9ef">else</span> <span style="color:#66d9ef">if</span> (a <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">1</span>){
</span></span><span style="display:flex;"><span>      theta[i] <span style="color:#f92672">&lt;-</span>  theta_star
</span></span><span style="display:flex;"><span>      accepted <span style="color:#f92672">&lt;-</span> accepted<span style="color:#ae81ff">+1</span>
</span></span><span style="display:flex;"><span>    } <span style="color:#66d9ef">else</span>{
</span></span><span style="display:flex;"><span>      r <span style="color:#f92672">=</span> <span style="color:#a6e22e">rbinom</span>(<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">1</span>,a)
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">if</span> (r <span style="color:#f92672">==</span> <span style="color:#ae81ff">1</span>){
</span></span><span style="display:flex;"><span>        theta[i] <span style="color:#f92672">&lt;-</span>  theta_star
</span></span><span style="display:flex;"><span>        accepted <span style="color:#f92672">&lt;-</span> accepted<span style="color:#ae81ff">+1</span>
</span></span><span style="display:flex;"><span>      } <span style="color:#66d9ef">else</span>{
</span></span><span style="display:flex;"><span>        theta[i] <span style="color:#f92672">&lt;-</span>  theta[i<span style="color:#ae81ff">-1</span>]
</span></span><span style="display:flex;"><span>      }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>  acc[v] <span style="color:#f92672">&lt;-</span> accepted<span style="color:#f92672">/</span>nit
</span></span><span style="display:flex;"><span>  post_pdf <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">lapply</span>(theta, logpostfunc, data<span style="color:#f92672">=</span>samplesPL)
</span></span><span style="display:flex;"><span>  theta_selected <span style="color:#f92672">&lt;-</span> theta<span style="color:#a6e22e">[which.max</span>(post_pdf)]
</span></span><span style="display:flex;"><span>  params[v] <span style="color:#f92672">&lt;-</span> theta_selected
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">setTxtProgressBar</span>(pb,v)
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span>params <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">as.numeric</span>(params)
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">plot</span>(d, xlab <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;alpha&#34;</span>, ylab <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;Density&#34;</span>, main <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;Density of alpha on the posterior&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">abline</span>(v<span style="color:#f92672">=</span>d<span style="color:#f92672">$</span>x[i], col<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;blue&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">abline</span>(v<span style="color:#f92672">=</span>alpha, col<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;red&#34;</span>)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span><span style="color:#a6e22e">mean</span>(params)
</span></span></code></pre></div><p>The MCMC algorithm implementation for the rest of the cases is a bit more complex as it involves random walks in higher dimensions. It can be found on my GitHub page.</p>
<h2 id="results">Results<a hidden class="anchor" aria-hidden="true" href="#results">#</a></h2>
<p>The simulation discussed above is implemented in R. For each case, the same samples are used, which are drawn from the distribution with the true parameters using Accept-Reject sampling. We generate 355 samples from the distribution with the true parameters, \( \alpha=2.2 \), \( \lambda=0.3 \), and \( \xmin=1.1 \), and use the same for inference in the three cases discussed above. In each of the three cases, the Metropolis-Hasting algorithm was used to draw 1000 samples \( {\boldsymbol{\phi}^{[1]}, \boldsymbol{\phi}^{[2]} \dots \boldsymbol{\phi}^{[1000]}} \) from the posterior, and \( \hat{\boldsymbol{\phi}} = \text{argmax}_{\boldsymbol{\phi}} \ p(\boldphi \ | \ \mathcal{D}) \) is calculated, where, \( \mathcal{D} \) is the sample generated from the distribution with known true parameters. This is repeated 100 times to calculate the estimate (\( \hat{\boldsymbol{\phi}} \)) at each iteration.</p>
<p>As we can see from Fig (1-6), we have the set of estimates for the parameters in each case, which are very close to the true value used during the simulation. When priors are more informative (case 2 and case 3), and when the number of estimable parameters is lower (case 1 and 2) we have better estimates of the parameters.</p>
<table>
<thead>
<tr>
<th>Case</th>
<th>Parameter</th>
<th>True</th>
<th>Estimated</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>\( \alpha \)</td>
<td>2.2</td>
<td>2.05</td>
</tr>
<tr>
<td>2</td>
<td>\( \alpha \)</td>
<td>2.2</td>
<td>2.19</td>
</tr>
<tr>
<td>2</td>
<td>\( \xmin \)</td>
<td>1.1</td>
<td>1.38</td>
</tr>
<tr>
<td>3</td>
<td>\( \alpha \)</td>
<td>2.2</td>
<td>2.51</td>
</tr>
<tr>
<td>3</td>
<td>\( \lambda \)</td>
<td>0.3</td>
<td>0.29</td>
</tr>
<tr>
<td>3</td>
<td>\( \xmin \)</td>
<td>1.1</td>
<td>1.29</td>
</tr>
</tbody>
</table>
<p style="text-align: center; font-style: italic; color: #808080;">
  <small>Table 1: Results of the estimation</small>
</p>
<p><img loading="lazy" src="/stats/mcmc_powerlaw/100it_case1.jpg" alt="100it1"  />
</p>
<p style="text-align: center; font-style: italic; color: #808080;">
  <small>
  Density plot for \hat{\alpha} after 100 iterations in Case 1
  </small>
</p>
<p><img loading="lazy" src="/stats/mcmc_powerlaw/100it_case2.jpg" alt="100it2"  />
</p>
<p style="text-align: center; font-style: italic; color: #808080;">
  <small>
  Density plot for $\hat{\alpha}$ after 100 iterations in Case 2
  </small>
</p>
<p><img loading="lazy" src="/stats/mcmc_powerlaw/100it_case2_xmin.jpg" alt="100it2xmin"  />
</p>
<p style="text-align: center; font-style: italic; color: #808080;">
  <small>
  Density plot for $\hat{\xmin}$ after 100 iterations in Case 2
  </small>
</p>
<p><img loading="lazy" src="/stats/mcmc_powerlaw/100it_case3_alpha.jpg" alt="100it3xmin"  />
</p>
<p style="text-align: center; font-style: italic; color: #808080;">
  <small>
  Density plot for $\hat{\xmin}$ after 100 iterations in Case 3
  </small>
</p>
<p><img loading="lazy" src="/stats/mcmc_powerlaw/100it_case3_alpha.jpg" alt="100it3alpha"  />
</p>
<p style="text-align: center; font-style: italic; color: #808080;">
  <small>
  Density plot for $\hat{\xmin}$ after 100 iterations in Case 3
  </small>
</p>
<p><img loading="lazy" src="/stats/mcmc_powerlaw/100it_case3_lambda.jpg" alt="100it3lambda"  />
</p>
<p style="text-align: center; font-style: italic; color: #808080;">
  <small>
  Density plot for $\hat{\lambda}$ after 100 iterations in Case 3
  </small>
</p>
<p><img loading="lazy" src="/stats/mcmc_powerlaw/100it_case3_xmin.jpg" alt="100it3xmin"  />
</p>
<p style="text-align: center; font-style: italic; color: #808080;">
  <small>
  Density plot for $\hat{\xmin}$ after 100 iterations in Case 3
  </small>
</p>
<h2 id="conclusion">Conclusion<a hidden class="anchor" aria-hidden="true" href="#conclusion">#</a></h2>
<p>In this research, we used MCMC for Bayesian parameter estimation from a power-law distribution with an exponential cutoff. First, we implemented an Accept-Reject method to sample from the distribution for later inference. Then, we derived Jeffrey&rsquo;s prior for one of the cases and used the Metropolis-Hasting algorithm to sample from the prior. For the proposal function, we derived the inverse transform sampling function for the traditional power-law distribution. Parameters were then estimated from the posterior samples by finding the mode.</p>
<p>In disciplines where we encounter power-law distributions in empirical data, having prior knowledge of the parameters and their bounds can significantly improve Bayesian estimations as observed. Even though this method can be used for estimation, for case 3, efficiency was as low as 15%. For inference on higher parameter dimensions, Hamiltonian Monte-Carlo can be used to yield higher efficiency.</p>
<h2 id="references">References<a hidden class="anchor" aria-hidden="true" href="#references">#</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-plaintext" data-lang="plaintext"><span style="display:flex;"><span>1. A. Clauset, C. R. Shalizi, and M. E. J. Newman, “Power-Law Distributions in Empirical Data,” SIAM Review, vol. 51, no. 4. Society for Industrial &amp; Applied Mathematics (SIAM), pp. 661–703, Nov. 04, 2009. doi: 10.1137/070710111
</span></span><span style="display:flex;"><span>2. Z. Zhu and R. A. Marcus, “A Maximum Likelihood Method for Power-law Distributions That Does Not Break Down When the Slope Is Close to Unity,” The Journal of Physical Chemistry C, vol. 116, no. 27. American Chemical Society (ACS), pp. 14690–14693, Jun. 20, 2012. doi: 10.1021/jp303697j
</span></span><span style="display:flex;"><span>3. F. Olmez, P. R. Kramer, J. Fricks, D. R. Schmidt, and J. Best, “Penalized KS method to fit data sets with power-law distribution over a bounded subinterval,” Journal of Statistical Computation and Simulation, vol. 91, no. 8. Informa UK Limited, pp. 1524–1563, Jan. 14, 2021. doi: 10.1080/00949655.2020.1861281
</span></span><span style="display:flex;"><span>4. B. Nettasinghe and V. Krishnamurthy, “Maximum Likelihood Estimation of Power-law Degree Distributions via Friendship Paradox-based Sampling,” ACM Transactions on Knowledge Discovery from Data, vol. 15, no. 6. Association for Computing Machinery (ACM), pp. 1–28, May 19, 2021. doi: 10.1145/3451166
</span></span><span style="display:flex;"><span>5. Harney, Hanns L. Bayesian inference : parameter estimation and decisions. Berlin New York: Springer, 2003
</span></span><span style="display:flex;"><span>6. F. Pennini and A. Plastino, “Power-law distributions and Fisher’s information measure,” Physica A: Statistical Mechanics and its Applications, vol. 334, no. 1–2. Elsevier BV, pp. 132–138, Mar. 2004. doi: 10.1016/j.physa.2003.10.076
</span></span><span style="display:flex;"><span>7. Liu, Jun S. Monte Carlo strategies in scientific computing. New York: Springer, 2008
</span></span><span style="display:flex;"><span>8. Casella, George, and Roger L. Berger. Statistical inference. Australia Pacific Grove, CA: Thomson Learning, 2002
</span></span><span style="display:flex;"><span>9. Michael I. Jordan Jeffreys Priors and Reference Priors. Berkeley, CA: Bayesian Modeling and Inference February 17, 2010
</span></span><span style="display:flex;"><span>10. Michael Betancourt: “A Conceptual Introduction to Hamiltonian Monte Carlo”, 2017; [http://arxiv.org/abs/1701.02434 arXiv:1701.02434
</span></span></code></pre></div>

  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="http://localhost:1313/tags/stats/">Stats</a></li>
      <li><a href="http://localhost:1313/tags/bayesian/">Bayesian</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2024 <a href="http://localhost:1313/">Chaos</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
